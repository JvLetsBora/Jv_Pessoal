# -*- coding: utf-8 -*-
"""Ponderada3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ro38_-IeECTHTpBmQRD5vgfg9k8Lr2Ij
"""

!pip install -U -q PyDrive

!pip install -U -q pyarrow

# importações necessarias
import pandas as pd
import os
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
import warnings
import shutil
warnings.filterwarnings('ignore')
import plotly.express as px
import pyarrow as pa
import pyarrow.parquet as pq

# Download dos dados para esta máquina virtual
shutil.unpack_archive(f"/content/drive/MyDrive/Pessoal/archive.zip", "./dataset")
#shutil.unpack_archive(f"/content/dataset/06120028.zip", "./dataset")
df_read = pd.read_csv('/content/dataset/Activity_history.csv')

df_read.isna().sum()

df_traino = df_read.dropna()

df_traino

df_traino["App name"].unique()



colunas_interresse = [
    "WhatsApp", "Instagram", "Gmail", "YouTube"
]

novo_df = df_traino.groupby(['App name', 'Date'])['Duration'].sum().reset_index()

segundos = df_traino["Duration"]

from numba.core.types.scalars import Float
segundos = []
for time in df_traino["Duration"]:
  a = time.split(":")
  b = (int(a[0])*100000) + (int(a[1])*1000) + (int(a[2])*10)
  segundos.append(b)

df_traino["Duration"] = segundos

df_traino

df_filtrado = df_traino[df_traino['App name'].isin(colunas_interresse)]

df_traino = df_filtrado

from numba.core.types.scalars import Float
times = []
for time in df_traino["Time"]:
  a = time.split(":")
  a2 = a[2].split(" ")
  b = (int(a[0])*100000) + (int(a[1])*1000) + (int(a2[0])*10)
  times.append(b)

df_traino["Time"] = times

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

lb = LabelEncoder()


apps = lb.fit_transform(df_traino["App name"])
apps

df_traino["labels_app"] = apps
df_traino

oneHot = OneHotEncoder()
arr = oneHot.fit_transform(df_traino[["labels_app"]]).toarray()
arr

one_hot_df = pd.DataFrame(arr, columns=[f'App_id_{i}' for i in range(arr.shape[1])])
one_hot_df

new_df = df = pd.concat([df_traino, one_hot_df], axis=1)
new_df = new_df.drop(["App name","labels_app","Date" ],axis=1)

new_df

from sklearn.preprocessing import MinMaxScaler

# Suponha que você tenha um DataFrame 'df' com características numéricas que você deseja escalar

# Crie uma instância do MinMaxScaler
scaler = MinMaxScaler()

# Ajuste e transforme os dados
df_scaled = scaler.fit_transform(new_df[["Time"]])

# O resultado é uma matriz NumPy, você pode convertê-la de volta em um DataFrame, se desejar
df_scaled = pd.DataFrame(df_scaled, columns=["Time"])

#new_df["Time"]=df_scaled

new_df=new_df.dropna()

new_df.head(100)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Suponha que você tenha um DataFrame 'df' com suas características e rótulos de preço
X = new_df.drop('Duration', axis=1)  # Features
y = new_df['Duration']  # Target variable

# Divida os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crie um modelo de regressão linear
model = LinearRegression()

# Treine o modelo
model.fit(X_train, y_train)

# Faça previsões no conjunto de teste
y_pred = model.predict(X_test)

# Avalie o modelo
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("Root Mean Squared Error:", rmse)
print("R-squared:", r2)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Avalie o modelo usando várias métricas
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')


print("Acurácia:", accuracy)
print("Precisão:", precision)
print("Revocação:", recall)
print("F1-Score:", f1)

data = [
    [528410.0, 0.0, 0.0, 1.0, 0.0],

]

y_pred = model.predict(
    data
)
y_pred



